apiVersion: v1
kind: ConfigMap
metadata:
  name: spark-entrypoint
  namespace: data-pipeline
data:
  entrypoint.sh: |
    #!/bin/bash
    SPARK_WORKLOAD=$1
    echo "SPARK_WORKLOAD: $SPARK_WORKLOAD"

    MASTER_URL="${SPARK_MASTER:-spark://spark-master:7077}"
    
    unset SPARK_MASTER

    if [ "$SPARK_WORKLOAD" = "master" ]; then
        start-master.sh
    elif [ "$SPARK_WORKLOAD" = "worker" ]; then
        start-worker.sh "$MASTER_URL"
    elif [ "$SPARK_WORKLOAD" = "history" ]; then
        start-history-server.sh
    else
        echo "Unknown SPARK_WORKLOAD: $SPARK_WORKLOAD"
        exit 1
    fi
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: spark-config
  namespace: data-pipeline
data:
  spark-defaults.conf: |
    spark.master                                spark://spark-master:7077
    spark.eventLog.enabled                      true
    spark.eventLog.dir                          /opt/spark/spark-events
    spark.history.fs.logDirectory               /opt/spark/spark-events

    spark.hadoop.fs.s3a.endpoint                http://minio-svc:9000
    spark.hadoop.fs.s3a.path.style.access       true
    spark.hadoop.fs.s3a.impl                    org.apache.hadoop.fs.s3a.S3AFileSystem
    spark.hadoop.fs.s3a.connection.ssl.enabled  false

    spark.sql.extensions                        org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions

    spark.sql.catalog.bronze                    org.apache.iceberg.spark.SparkCatalog
    spark.sql.catalog.bronze.type               hadoop
    spark.sql.catalog.bronze.warehouse          s3a://bronze

    spark.sql.catalog.silver                    org.apache.iceberg.spark.SparkCatalog
    spark.sql.catalog.silver.type               hadoop
    spark.sql.catalog.silver.warehouse          s3a://silver

    spark.sql.catalog.gold                      org.apache.iceberg.spark.SparkCatalog
    spark.sql.catalog.gold.type                 hadoop
    spark.sql.catalog.gold.warehouse            s3a://gold

    spark.jars                                  /opt/spark/jars/iceberg-spark-runtime-3.5_2.12-1.7.1.jar,/opt/spark/jars/iceberg-aws-bundle-1.7.1.jar
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: spark-env
  namespace: data-pipeline
data:
  SPARK_NO_DAEMONIZE: "true"
  SPARK_MASTER_PORT: "7077"
  SPARK_DAEMON_JAVA_OPTS: "-Dspark.ui.bindAddress=0.0.0.0"

---
apiVersion: v1
kind: Secret
metadata:
  name: spark-s3-credential
  namespace: data-pipeline
type: Opaque
stringData:
  AWS_ACCESS_KEY_ID: minio_access_key
  AWS_SECRET_ACCESS_KEY: minio_secret_key
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: spark-events
  namespace: data-pipeline
spec:
  resources:
    requests:
      storage: 2Gi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteOnce
  storageClassName: standard
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: spark-data
  namespace: data-pipeline
spec:
  resources:
    requests:
      storage: 4Gi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteOnce
  storageClassName: standard
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: spark-apps
  namespace: data-pipeline
spec:
  resources:
    requests:
      storage: 2Gi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteOnce
  storageClassName: standard
---
# ==================== SPARK MASTER ====================
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark-master
  namespace: data-pipeline
  labels:
    app: spark
    component: master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: spark
      component: master
  template:
    metadata:
      labels:
        app: spark
        component: master
    spec:
      hostname: spark-master
      containers:
        - name: spark-master
          image: remmydream/spark-image:v1.0
          command: ["/bin/bash", "/entrypoint/entrypoint.sh", "master"]
          ports:
            - name: web-ui
              containerPort: 8080
            - name: master
              containerPort: 7077
          env:
            - name: SPARK_MASTER_HOST
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: SPARK_LOCAL_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
          envFrom:
            - configMapRef:
                name: spark-env
            - secretRef:
                name: spark-s3-credential
          volumeMounts:
            - name: entrypoint
              mountPath: /entrypoint
            - name: spark-config
              mountPath: /opt/spark/conf/spark-defaults.conf
              subPath: spark-defaults.conf
            - name: spark-events
              mountPath: /opt/spark/spark-events
            - name: spark-data
              mountPath: /opt/spark/data
            - name: spark-apps
              mountPath: /opt/spark/apps
          resources:
            requests:
              memory: "512Mi"
              cpu: "250m"
            limits:
              memory: "2Gi"
              cpu: "1000m"
          livenessProbe:
            httpGet:
              path: /
              port: 8080
            initialDelaySeconds: 60
            periodSeconds: 10
          readinessProbe:
            httpGet:
              path: /
              port: 8080
            initialDelaySeconds: 30
            periodSeconds: 10
      volumes:
        - name: entrypoint
          configMap:
            name: spark-entrypoint
            defaultMode: 0755
        - name: spark-config
          configMap:
            name: spark-config
        - name: spark-events
          persistentVolumeClaim:
            claimName: spark-events
        - name: spark-data
          persistentVolumeClaim:
            claimName: spark-data
        - name: spark-apps
          persistentVolumeClaim:
            claimName: spark-apps
---
apiVersion: v1
kind: Service
metadata:
  name: spark-master
  namespace: data-pipeline
  labels:
    app: spark
    component: master
spec:
  type: ClusterIP
  ports:
    - name: web-ui
      port: 8080
      targetPort: 8080
    - name: master
      port: 7077
      targetPort: 7077
  selector:
    app: spark
    component: master
---
# ==================== SPARK WORKER ====================
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark-worker
  namespace: data-pipeline
  labels:
    app: spark
    component: worker
spec:
  replicas: 2
  selector:
    matchLabels:
      app: spark
      component: worker
  template:
    metadata:
      labels:
        app: spark
        component: worker
    spec:
      containers:
        - name: spark-worker
          image: remmydream/spark-image:v1.0
          command: ["/bin/bash", "/entrypoint/entrypoint.sh", "worker"]
          ports:
            - name: web-ui
              containerPort: 8081
          env:
            - name: SPARK_LOCAL_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: SPARK_WORKER_HOST
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: SPARK_MASTER
              value: "spark://spark-master:7077"
          envFrom:
            - configMapRef:
                name: spark-env
            - secretRef:
                name: spark-s3-credential
          volumeMounts:
            - name: entrypoint
              mountPath: /entrypoint
            - name: spark-config
              mountPath: /opt/spark/conf/spark-defaults.conf
              subPath: spark-defaults.conf
            - name: spark-events
              mountPath: /opt/spark/spark-events
            - name: spark-data
              mountPath: /opt/spark/data
            - name: spark-apps
              mountPath: /opt/spark/apps
          resources:
            requests:
              memory: "1Gi"
              cpu: "500m"
            limits:
              memory: "4Gi"
              cpu: "2000m"
      volumes:
        - name: entrypoint
          configMap:
            name: spark-entrypoint
            defaultMode: 0755
        - name: spark-config
          configMap:
            name: spark-config
        - name: spark-events
          persistentVolumeClaim:
            claimName: spark-events
        - name: spark-data
          persistentVolumeClaim:
            claimName: spark-data
        - name: spark-apps
          persistentVolumeClaim:
            claimName: spark-apps
---
# ==================== SPARK HISTORY SERVER ====================
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark-history
  namespace: data-pipeline
  labels:
    app: spark
    component: history
spec:
  replicas: 1
  selector:
    matchLabels:
      app: spark
      component: history
  template:
    metadata:
      labels:
        app: spark
        component: history
    spec:
      containers:
        - name: spark-history
          image: remmydream/spark-image:v1.0
          command: ["/bin/bash", "/entrypoint/entrypoint.sh", "history"]
          ports:
            - name: web-ui
              containerPort: 18080
          env:
            - name: SPARK_LOCAL_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
          envFrom:
            - configMapRef:
                name: spark-env
            - secretRef:
                name: spark-s3-credential
          volumeMounts:
            - name: entrypoint
              mountPath: /entrypoint
            - name: spark-config
              mountPath: /opt/spark/conf/spark-defaults.conf
              subPath: spark-defaults.conf
            - name: spark-events
              mountPath: /opt/spark/spark-events
          resources:
            requests:
              memory: "256Mi"
              cpu: "250m"
            limits:
              memory: "1Gi"
              cpu: "500m"
          livenessProbe:
            httpGet:
              path: /
              port: 18080
            initialDelaySeconds: 60
            periodSeconds: 10
          readinessProbe:
            httpGet:
              path: /
              port: 18080
            initialDelaySeconds: 30
            periodSeconds: 10
      volumes:
        - name: entrypoint
          configMap:
            name: spark-entrypoint
            defaultMode: 0755
        - name: spark-config
          configMap:
            name: spark-config
        - name: spark-events
          persistentVolumeClaim:
            claimName: spark-events
---
apiVersion: v1
kind: Service
metadata:
  name: spark-history
  namespace: data-pipeline
  labels:
    app: spark
    component: history
spec:
  type: ClusterIP
  ports:
    - name: web-ui
      port: 18080
      targetPort: 18080
  selector:
    app: spark
    component: history