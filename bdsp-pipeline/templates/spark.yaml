{{- if .Values.spark.enabled }}
---
# ConfigMap for Spark configuration files
apiVersion: v1
kind: ConfigMap
metadata:
  name: spark-config
  namespace: {{ include "bdsp-pipeline.namespace" . }}
  labels:
    {{- include "bdsp-pipeline.labels" . | nindent 4 }}
    app: spark
data:
  spark-defaults.conf: |
    spark.master                            spark://spark-master:7077
    spark.eventLog.enabled                  true
    spark.eventLog.dir                      /opt/spark/spark-events
    spark.history.fs.logDirectory           /opt/spark/spark-events

    spark.hadoop.fs.s3a.path.style.access   true
    spark.hadoop.fs.s3a.impl                org.apache.hadoop.fs.s3a.S3AFileSystem
    spark.hadoop.fs.s3a.connection.ssl.enabled  false

    spark.sql.extensions                    org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions

    spark.sql.catalog.bronze                org.apache.iceberg.spark.SparkCatalog
    spark.sql.catalog.bronze.type           hadoop
    spark.sql.catalog.bronze.warehouse      s3a://bronze

    spark.sql.catalog.silver                org.apache.iceberg.spark.SparkCatalog
    spark.sql.catalog.silver.type           hadoop
    spark.sql.catalog.silver.warehouse      s3a://silver

    spark.sql.catalog.gold                  org.apache.iceberg.spark.SparkCatalog
    spark.sql.catalog.gold.type             hadoop
    spark.sql.catalog.gold.warehouse        s3a://gold

    spark.jars                              /opt/spark/jars/iceberg-spark-runtime-3.5_2.12-1.7.1.jar,/opt/spark/jars/iceberg-aws-bundle-1.7.1.jar

---
# PersistentVolumeClaim for Spark event logs
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: spark-logs
  namespace: {{ include "bdsp-pipeline.namespace" . }}
  labels:
    {{- include "bdsp-pipeline.labels" . | nindent 4 }}
    app: spark
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: {{ .Values.spark.persistence.logsSize }}
  {{- if .Values.spark.persistence.storageClass }}
  storageClassName: {{ .Values.spark.persistence.storageClass }}
  {{- end }}

---
# PersistentVolumeClaim for Spark applications
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: spark-apps
  namespace: {{ include "bdsp-pipeline.namespace" . }}
  labels:
    {{- include "bdsp-pipeline.labels" . | nindent 4 }}
    app: spark
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: {{ .Values.spark.persistence.appsSize }}
  {{- if .Values.spark.persistence.storageClass }}
  storageClassName: {{ .Values.spark.persistence.storageClass }}
  {{- end }}

---
# Spark Master Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark-master
  namespace: {{ include "bdsp-pipeline.namespace" . }}
  labels:
    {{- include "bdsp-pipeline.labels" . | nindent 4 }}
    app: spark-master
spec:
  replicas: {{ .Values.spark.master.replicas }}
  selector:
    matchLabels:
      app: spark-master
  template:
    metadata:
      labels:
        app: spark-master
        {{- include "bdsp-pipeline.selectorLabels" . | nindent 8 }}
    spec:
      enableServiceLinks: false
      containers:
      - name: spark-master
        image: "{{ .Values.spark.image.repository }}:{{ .Values.spark.image.tag }}"
        imagePullPolicy: {{ .Values.spark.image.pullPolicy }}
        command: ["/opt/spark/entrypoint.sh", "master"]
        workingDir: /opt/spark
        env:
        - name: SPARK_NO_DAEMONIZE
          value: {{ .Values.spark.env.sparkNoDaemonize | quote }}
        - name: SPARK_MASTER_HOST
          value: {{ .Values.spark.env.sparkMasterHost | quote }}
        - name: SPARK_DRIVER_HOST
          value: {{ .Values.spark.env.sparkDriverHost | quote }}
        - name: SPARK_MASTER_PORT
          value: {{ .Values.spark.env.sparkMasterPort | quote }}
        - name: SPARK_MASTER
          value: "spark://{{ .Values.spark.env.sparkMasterHost }}:{{ .Values.spark.env.sparkMasterPort }}"
        - name: SPARK_DRIVER_BIND_ADDRESS
          value: {{ .Values.spark.env.sparkDriverBindAddress | quote }}
        {{- if .Values.spark.env.extraEnvVars }}
        {{- toYaml .Values.spark.env.extraEnvVars | nindent 8 }}
        {{- end }}
        ports:
        - containerPort: 8080
          name: webui
        - containerPort: 7077
          name: spark
        volumeMounts:
        - name: spark-logs
          mountPath: /opt/spark/spark-events
        - name: spark-apps
          mountPath: /opt/spark/apps
        - name: spark-config
          mountPath: /opt/spark/conf/spark-defaults.conf
          subPath: spark-defaults.conf
        {{- if .Values.spark.master.resources }}
        resources:
          {{- toYaml .Values.spark.master.resources | nindent 10 }}
        {{- end }}
        {{- if .Values.spark.master.livenessProbe.enabled }}
        livenessProbe:
          httpGet:
            path: /
            port: 8080
          initialDelaySeconds: {{ .Values.spark.master.livenessProbe.initialDelaySeconds }}
          periodSeconds: {{ .Values.spark.master.livenessProbe.periodSeconds }}
          timeoutSeconds: {{ .Values.spark.master.livenessProbe.timeoutSeconds }}
          failureThreshold: {{ .Values.spark.master.livenessProbe.failureThreshold }}
        {{- end }}
        {{- if .Values.spark.master.readinessProbe.enabled }}
        readinessProbe:
          httpGet:
            path: /
            port: 8080
          initialDelaySeconds: {{ .Values.spark.master.readinessProbe.initialDelaySeconds }}
          periodSeconds: {{ .Values.spark.master.readinessProbe.periodSeconds }}
          timeoutSeconds: {{ .Values.spark.master.readinessProbe.timeoutSeconds }}
          failureThreshold: {{ .Values.spark.master.readinessProbe.failureThreshold }}
        {{- end }}
      volumes:
      - name: spark-logs
        persistentVolumeClaim:
          claimName: spark-logs
      - name: spark-apps
        persistentVolumeClaim:
          claimName: spark-apps
      - name: spark-config
        configMap:
          name: spark-config

---
# Spark Master Service
apiVersion: v1
kind: Service
metadata:
  name: spark-master
  namespace: {{ include "bdsp-pipeline.namespace" . }}
  labels:
    {{- include "bdsp-pipeline.labels" . | nindent 4 }}
    app: spark-master
spec:
  type: {{ .Values.spark.master.service.type }}
  selector:
    app: spark-master
  ports:
  - name: webui
    port: 8080
    targetPort: 8080
    {{- if and (eq .Values.spark.master.service.type "NodePort") .Values.spark.master.service.webuiNodePort }}
    nodePort: {{ .Values.spark.master.service.webuiNodePort }}
    {{- end }}
  - name: spark
    port: 7077
    targetPort: 7077
    {{- if and (eq .Values.spark.master.service.type "NodePort") .Values.spark.master.service.sparkNodePort }}
    nodePort: {{ .Values.spark.master.service.sparkNodePort }}
    {{- end }}

---
# Spark Worker Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark-worker
  namespace: {{ include "bdsp-pipeline.namespace" . }}
  labels:
    {{- include "bdsp-pipeline.labels" . | nindent 4 }}
    app: spark-worker
spec:
  replicas: {{ .Values.spark.worker.replicas }}
  selector:
    matchLabels:
      app: spark-worker
  template:
    metadata:
      labels:
        app: spark-worker
        {{- include "bdsp-pipeline.selectorLabels" . | nindent 8 }}
    spec:
      enableServiceLinks: false
      containers:
      - name: spark-worker
        image: "{{ .Values.spark.image.repository }}:{{ .Values.spark.image.tag }}"
        imagePullPolicy: {{ .Values.spark.image.pullPolicy }}
        command: ["/opt/spark/entrypoint.sh", "worker"]
        workingDir: /opt/spark
        env:
        - name: SPARK_NO_DAEMONIZE
          value: {{ .Values.spark.env.sparkNoDaemonize | quote }}
        - name: SPARK_MASTER_HOST
          value: {{ .Values.spark.env.sparkMasterHost | quote }}
        - name: SPARK_DRIVER_HOST
          value: {{ .Values.spark.env.sparkDriverHost | quote }}
        - name: SPARK_MASTER_PORT
          value: {{ .Values.spark.env.sparkMasterPort | quote }}
        - name: SPARK_MASTER
          value: "spark://{{ .Values.spark.env.sparkMasterHost }}:{{ .Values.spark.env.sparkMasterPort }}"
        - name: SPARK_DRIVER_BIND_ADDRESS
          value: {{ .Values.spark.env.sparkDriverBindAddress | quote }}
        {{- if .Values.spark.env.extraEnvVars }}
        {{- toYaml .Values.spark.env.extraEnvVars | nindent 8 }}
        {{- end }}
        ports:
        - containerPort: 8081
          name: webui
        volumeMounts:
        - name: spark-logs
          mountPath: /opt/spark/spark-events
        - name: spark-apps
          mountPath: /opt/spark/apps
        - name: spark-config
          mountPath: /opt/spark/conf/spark-defaults.conf
          subPath: spark-defaults.conf
        {{- if .Values.spark.worker.resources }}
        resources:
          {{- toYaml .Values.spark.worker.resources | nindent 10 }}
        {{- end }}
      volumes:
      - name: spark-logs
        persistentVolumeClaim:
          claimName: spark-logs
      - name: spark-apps
        persistentVolumeClaim:
          claimName: spark-apps
      - name: spark-config
        configMap:
          name: spark-config

---
# Spark Worker Service (for worker WebUI)
apiVersion: v1
kind: Service
metadata:
  name: spark-worker
  namespace: {{ include "bdsp-pipeline.namespace" . }}
  labels:
    {{- include "bdsp-pipeline.labels" . | nindent 4 }}
    app: spark-worker
spec:
  type: {{ .Values.spark.worker.service.type }}
  selector:
    app: spark-worker
  ports:
  - name: webui
    port: 8081
    targetPort: 8081
    {{- if and (eq .Values.spark.worker.service.type "NodePort") .Values.spark.worker.service.webuiNodePort }}
    nodePort: {{ .Values.spark.worker.service.webuiNodePort }}
    {{- end }}

---
# Spark History Server Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark-history-server
  namespace: {{ include "bdsp-pipeline.namespace" . }}
  labels:
    {{- include "bdsp-pipeline.labels" . | nindent 4 }}
    app: spark-history-server
spec:
  replicas: {{ .Values.spark.historyServer.replicas }}
  selector:
    matchLabels:
      app: spark-history-server
  template:
    metadata:
      labels:
        app: spark-history-server
        {{- include "bdsp-pipeline.selectorLabels" . | nindent 8 }}
    spec:
      enableServiceLinks: false
      containers:
      - name: spark-history-server
        image: "{{ .Values.spark.image.repository }}:{{ .Values.spark.image.tag }}"
        imagePullPolicy: {{ .Values.spark.image.pullPolicy }}
        command: ["/opt/spark/entrypoint.sh", "history"]
        workingDir: /opt/spark
        env:
        - name: SPARK_NO_DAEMONIZE
          value: {{ .Values.spark.env.sparkNoDaemonize | quote }}
        - name: SPARK_MASTER_HOST
          value: {{ .Values.spark.env.sparkMasterHost | quote }}
        - name: SPARK_DRIVER_HOST
          value: {{ .Values.spark.env.sparkDriverHost | quote }}
        - name: SPARK_MASTER_PORT
          value: {{ .Values.spark.env.sparkMasterPort | quote }}
        - name: SPARK_MASTER
          value: "spark://{{ .Values.spark.env.sparkMasterHost }}:{{ .Values.spark.env.sparkMasterPort }}"
        - name: SPARK_DRIVER_BIND_ADDRESS
          value: {{ .Values.spark.env.sparkDriverBindAddress | quote }}
        {{- if .Values.spark.env.extraEnvVars }}
        {{- toYaml .Values.spark.env.extraEnvVars | nindent 8 }}
        {{- end }}
        ports:
        - containerPort: 18080
          name: webui
        volumeMounts:
        - name: spark-logs
          mountPath: /opt/spark/spark-events
        - name: spark-apps
          mountPath: /opt/spark/apps
        - name: spark-config
          mountPath: /opt/spark/conf/spark-defaults.conf
          subPath: spark-defaults.conf
        {{- if .Values.spark.historyServer.resources }}
        resources:
          {{- toYaml .Values.spark.historyServer.resources | nindent 10 }}
        {{- end }}
        {{- if .Values.spark.historyServer.livenessProbe.enabled }}
        livenessProbe:
          httpGet:
            path: /
            port: 18080
          initialDelaySeconds: {{ .Values.spark.historyServer.livenessProbe.initialDelaySeconds }}
          periodSeconds: {{ .Values.spark.historyServer.livenessProbe.periodSeconds }}
          timeoutSeconds: {{ .Values.spark.historyServer.livenessProbe.timeoutSeconds }}
          failureThreshold: {{ .Values.spark.historyServer.livenessProbe.failureThreshold }}
        {{- end }}
        {{- if .Values.spark.historyServer.readinessProbe.enabled }}
        readinessProbe:
          httpGet:
            path: /
            port: 18080
          initialDelaySeconds: {{ .Values.spark.historyServer.readinessProbe.initialDelaySeconds }}
          periodSeconds: {{ .Values.spark.historyServer.readinessProbe.periodSeconds }}
          timeoutSeconds: {{ .Values.spark.historyServer.readinessProbe.timeoutSeconds }}
          failureThreshold: {{ .Values.spark.historyServer.readinessProbe.failureThreshold }}
        {{- end }}
      volumes:
      - name: spark-logs
        persistentVolumeClaim:
          claimName: spark-logs
      - name: spark-apps
        persistentVolumeClaim:
          claimName: spark-apps
      - name: spark-config
        configMap:
          name: spark-config

---
# Spark History Server Service
apiVersion: v1
kind: Service
metadata:
  name: spark-history-server
  namespace: {{ include "bdsp-pipeline.namespace" . }}
  labels:
    {{- include "bdsp-pipeline.labels" . | nindent 4 }}
    app: spark-history-server
spec:
  type: {{ .Values.spark.historyServer.service.type }}
  selector:
    app: spark-history-server
  ports:
  - name: webui
    port: 18080
    targetPort: 18080
    {{- if and (eq .Values.spark.historyServer.service.type "NodePort") .Values.spark.historyServer.service.webuiNodePort }}
    nodePort: {{ .Values.spark.historyServer.service.webuiNodePort }}
    {{- end }}

{{- end }}
